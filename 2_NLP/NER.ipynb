{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Reference\n",
    "# https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2\n",
    "# https://github.com/scrapinghub/python-crfsuite/blob/master/examples/CoNLL%202002.ipynb\n",
    "\n",
    "host = 0\n",
    "# host = 4\n",
    "\n",
    "if host == 0:\n",
    "    path = '/Users/aron/Documents/GitHub/Perfume/2_NLP'\n",
    "elif host == 4:\n",
    "    path = r'/home/rserver/Data_Mining/personal_workspace/yz/Lab/CkipTagger/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增工作資料夾\n",
    "path_resource = path + '/Resource'\n",
    "path_function = path + '/Function'\n",
    "path_temp = path + '/Temp'\n",
    "path_export = path + '/Export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    95456\n",
       "Word              0\n",
       "POS               0\n",
       "Tag               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_resource + '/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "df = df[:100000]\n",
    "df.head()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4544, 10922, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-art</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-eve</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-geo</td>\n",
       "      <td>3303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-gpe</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-nat</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-org</td>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B-per</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-tim</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-art</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-eve</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-geo</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-gpe</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I-nat</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-org</td>\n",
       "      <td>1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I-per</td>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I-tim</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>84725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag  counts\n",
       "0   B-art      75\n",
       "1   B-eve      53\n",
       "2   B-geo    3303\n",
       "3   B-gpe    1740\n",
       "4   B-nat      30\n",
       "5   B-org    1876\n",
       "6   B-per    1668\n",
       "7   B-tim    1823\n",
       "8   I-art      43\n",
       "9   I-eve      47\n",
       "10  I-geo     690\n",
       "11  I-gpe      51\n",
       "12  I-nat      11\n",
       "13  I-org    1470\n",
       "14  I-per    1846\n",
       "15  I-tim     549\n",
       "16      O   84725"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Tag').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67000, 15507), (67000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Tag', axis=1)\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(X.to_dict('records'))\n",
    "y = df.Tag.values\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-core Algorithms\n",
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1-- Epoch 1\n",
      "\n",
      "-- Epoch 1\n",
      "\n",
      "-- Epoch 1-- Epoch 1\n",
      "\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 11.53, NNZs: 113, Bias: -3.000000, T: 67000, Avg. loss: 0.001060\n",
      "Total training time: 3.40 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 13.42, NNZs: 162, Bias: -4.000000, T: 67000, Avg. loss: 0.001642\n",
      "Total training time: 3.44 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 44.41, NNZs: 1127, Bias: -4.000000, T: 67000, Avg. loss: 0.017164\n",
      "Total training time: 3.48 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.43, NNZs: 57, Bias: -3.000000, T: 67000, Avg. loss: 0.000567\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 48.83, NNZs: 1578, Bias: -4.000000, T: 67000, Avg. loss: 0.022328\n",
      "Total training time: 3.53 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.90, NNZs: 1337, Bias: -4.000000, T: 67000, Avg. loss: 0.015328\n",
      "Total training time: 3.60 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  17 | elapsed:    3.6s remaining:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  17 | elapsed:    3.7s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  17 | elapsed:    3.8s remaining:    4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1Norm: 56.87, NNZs: 2044, Bias: -4.000000, T: 67000, Avg. loss: 0.034970\n",
      "\n",
      "Total training time: 3.61 seconds.\n",
      "-- Epoch 1Norm: 68.07, NNZs: 2642, Bias: -4.000000, T: 67000, Avg. loss: 0.041776\n",
      "\n",
      "Total training time: 3.62 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 10.44, NNZs: 106, Bias: -3.000000, T: 67000, Avg. loss: 0.001060\n",
      "Total training time: 3.36 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 11.45, NNZs: 96, Bias: -3.000000, T: 67000, Avg. loss: 0.000776\n",
      "Total training time: 3.40 seconds.\n",
      "Norm: 6.24, NNZs: 31, Bias: -3.000000, T: 67000, Avg. loss: 0.000209\n",
      "Total training time: 3.40 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  17 | elapsed:    7.0s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    7.1s remaining:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 35.13, NNZs: 803, Bias: -4.000000, T: 67000, Avg. loss: 0.011149\n",
      "Total training time: 3.50 seconds.\n",
      "Norm: 11.00, NNZs: 102, Bias: -3.000000, T: 67000, Avg. loss: 0.001209\n",
      "Total training time: 3.50 seconds.\n",
      "Norm: 53.57, NNZs: 1703, Bias: -4.000000, T: 67000, Avg. loss: 0.026224\n",
      "Total training time: 3.46 seconds.\n",
      "Norm: 30.53, NNZs: 672, Bias: -4.000000, T: 67000, Avg. loss: 0.012030\n",
      "Total training time: 3.42 seconds.\n",
      "Norm: 60.35, NNZs: 2091, Bias: -6.000000, T: 67000, Avg. loss: 0.026940\n",
      "Total training time: 3.47 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    7.2s remaining:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 73.89, NNZs: 2851, Bias: 4.000000, T: 67000, Avg. loss: 0.048866\n",
      "Total training time: 1.40 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(max_iter=5, n_jobs=-1, verbose=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        24\n",
      "       B-eve       0.11      0.05      0.07        19\n",
      "       B-geo       0.56      0.81      0.66      1085\n",
      "       B-gpe       0.92      0.78      0.84       556\n",
      "       B-nat       1.00      0.17      0.29        12\n",
      "       B-org       0.39      0.52      0.44       589\n",
      "       B-per       0.70      0.46      0.56       564\n",
      "       B-tim       0.91      0.63      0.75       611\n",
      "       I-art       0.00      0.00      0.00        12\n",
      "       I-eve       0.67      0.22      0.33        18\n",
      "       I-geo       0.75      0.42      0.54       230\n",
      "       I-gpe       1.00      0.07      0.13        14\n",
      "       I-nat       0.50      0.50      0.50         2\n",
      "       I-org       0.48      0.50      0.49       445\n",
      "       I-per       0.83      0.13      0.22       591\n",
      "       I-tim       0.36      0.18      0.24       194\n",
      "\n",
      "   micro avg       0.61      0.54      0.58      4966\n",
      "   macro avg       0.57      0.34      0.38      4966\n",
      "weighted avg       0.66      0.54      0.55      4966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=per.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear classifiers with SGD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.45      0.21      0.29        24\n",
      "       B-eve       0.33      0.05      0.09        19\n",
      "       B-geo       0.64      0.84      0.73      1085\n",
      "       B-gpe       0.87      0.61      0.72       556\n",
      "       B-nat       0.00      0.00      0.00        12\n",
      "       B-org       0.61      0.39      0.48       589\n",
      "       B-per       0.61      0.51      0.56       564\n",
      "       B-tim       0.92      0.63      0.75       611\n",
      "       I-art       0.00      0.00      0.00        12\n",
      "       I-eve       0.80      0.22      0.35        18\n",
      "       I-geo       0.77      0.47      0.58       230\n",
      "       I-gpe       0.00      0.00      0.00        14\n",
      "       I-nat       0.00      0.00      0.00         2\n",
      "       I-org       0.68      0.46      0.55       445\n",
      "       I-per       0.57      0.66      0.61       591\n",
      "       I-tim       0.67      0.02      0.04       194\n",
      "\n",
      "   micro avg       0.68      0.58      0.63      4966\n",
      "   macro avg       0.50      0.32      0.36      4966\n",
      "weighted avg       0.69      0.58      0.61      4966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Naive Bayes classifier for multinomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.06      0.17      0.09        24\n",
      "       B-eve       0.33      0.37      0.35        19\n",
      "       B-geo       0.70      0.63      0.66      1085\n",
      "       B-gpe       0.70      0.83      0.76       556\n",
      "       B-nat       0.35      0.50      0.41        12\n",
      "       B-org       0.41      0.44      0.43       589\n",
      "       B-per       0.44      0.47      0.46       564\n",
      "       B-tim       0.56      0.61      0.59       611\n",
      "       I-art       0.07      0.08      0.08        12\n",
      "       I-eve       0.46      0.33      0.39        18\n",
      "       I-geo       0.40      0.52      0.46       230\n",
      "       I-gpe       0.13      0.14      0.14        14\n",
      "       I-nat       0.00      0.00      0.00         2\n",
      "       I-org       0.50      0.51      0.51       445\n",
      "       I-per       0.53      0.50      0.51       591\n",
      "       I-tim       0.17      0.27      0.21       194\n",
      "\n",
      "   micro avg       0.52      0.56      0.54      4966\n",
      "   macro avg       0.36      0.40      0.38      4966\n",
      "weighted avg       0.54      0.56      0.54      4966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels = new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa = PassiveAggressiveClassifier()\n",
    "pa.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.19      0.12      0.15        24\n",
      "       B-eve       0.50      0.26      0.34        19\n",
      "       B-geo       0.58      0.88      0.70      1085\n",
      "       B-gpe       0.98      0.71      0.82       556\n",
      "       B-nat       0.50      0.33      0.40        12\n",
      "       B-org       0.60      0.32      0.42       589\n",
      "       B-per       0.84      0.42      0.56       564\n",
      "       B-tim       0.87      0.70      0.77       611\n",
      "       I-art       0.25      0.33      0.29        12\n",
      "       I-eve       0.42      0.28      0.33        18\n",
      "       I-geo       0.78      0.06      0.11       230\n",
      "       I-gpe       0.45      0.36      0.40        14\n",
      "       I-nat       0.20      0.50      0.29         2\n",
      "       I-org       0.45      0.66      0.54       445\n",
      "       I-per       0.61      0.67      0.64       591\n",
      "       I-tim       0.35      0.14      0.21       194\n",
      "\n",
      "   micro avg       0.64      0.60      0.62      4966\n",
      "   macro avg       0.54      0.42      0.44      4966\n",
      "weighted avg       0.68      0.60      0.60      4966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=pa.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Fields (CRFs)\n",
    "### sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn_crfsuite\n",
    "# from sklearn_crfsuite import scorers\n",
    "# from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
    "                                                           s['POS'].values.tolist(), \n",
    "                                                           s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Sentence: 4543</td>\n",
       "      <td>some</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Sentence: 4543</td>\n",
       "      <td>seriously</td>\n",
       "      <td>RB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Sentence: 4543</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Sentence: 4544</td>\n",
       "      <td>Demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Sentence: 4544</td>\n",
       "      <td>chanting</td>\n",
       "      <td>VBG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sentence #           Word  POS Tag\n",
       "0         Sentence: 1      Thousands  NNS   O\n",
       "1         Sentence: 1             of   IN   O\n",
       "2         Sentence: 1  demonstrators  NNS   O\n",
       "3         Sentence: 1           have  VBP   O\n",
       "4         Sentence: 1        marched  VBN   O\n",
       "...               ...            ...  ...  ..\n",
       "99995  Sentence: 4543           some   DT   O\n",
       "99996  Sentence: 4543      seriously   RB   O\n",
       "99997  Sentence: 4543              .    .   O\n",
       "99998  Sentence: 4544  Demonstrators  NNS   O\n",
       "99999  Sentence: 4544       chanting  VBG   O\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bias': 1.0,\n",
       "   'word.lower()': 'a',\n",
       "   'word[-3:]': 'A',\n",
       "   'word[-2:]': 'A',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'second',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'second',\n",
       "   'word[-3:]': 'ond',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'a',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'nominee',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'nominee',\n",
       "   'word[-3:]': 'nee',\n",
       "   'word[-2:]': 'ee',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'second',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'nominee',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'general',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'general',\n",
       "   'word[-3:]': 'ral',\n",
       "   'word[-2:]': 'al',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'sadeq',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'sadeq',\n",
       "   'word[-3:]': 'deq',\n",
       "   'word[-2:]': 'eq',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'general',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'mahsouli',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'mahsouli',\n",
       "   'word[-3:]': 'uli',\n",
       "   'word[-2:]': 'li',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'sadeq',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '-',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '-',\n",
       "   'word[-3:]': '-',\n",
       "   'word[-2:]': '-',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'mahsouli',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'a',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'a',\n",
       "   'word[-3:]': 'a',\n",
       "   'word[-2:]': 'a',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': '-',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'revolutionary',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'revolutionary',\n",
       "   'word[-3:]': 'ary',\n",
       "   'word[-2:]': 'ry',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'a',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'guards',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'guards',\n",
       "   'word[-3:]': 'rds',\n",
       "   'word[-2:]': 'ds',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'revolutionary',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'commander',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'commander',\n",
       "   'word[-3:]': 'der',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'guards',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'with',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'with',\n",
       "   'word[-3:]': 'ith',\n",
       "   'word[-2:]': 'th',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'commander',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'no',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'no',\n",
       "   'word[-3:]': 'no',\n",
       "   'word[-2:]': 'no',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'with',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'oil',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'oil',\n",
       "   'word[-3:]': 'oil',\n",
       "   'word[-2:]': 'il',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'no',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'experience',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'experience',\n",
       "   'word[-3:]': 'nce',\n",
       "   'word[-2:]': 'ce',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'oil',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '-',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ':',\n",
       "   '+1:postag[:2]': ':'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '-',\n",
       "   'word[-3:]': '-',\n",
       "   'word[-2:]': '-',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ':',\n",
       "   'postag[:2]': ':',\n",
       "   '-1:word.lower()': 'experience',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'withdrew',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'withdrew',\n",
       "   'word[-3:]': 'rew',\n",
       "   'word[-2:]': 'ew',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': '-',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ':',\n",
       "   '-1:postag[:2]': ':',\n",
       "   '+1:word.lower()': 'his',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP$',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'his',\n",
       "   'word[-3:]': 'his',\n",
       "   'word[-2:]': 'is',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP$',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'withdrew',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'candidacy',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'candidacy',\n",
       "   'word[-3:]': 'acy',\n",
       "   'word[-2:]': 'cy',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'his',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP$',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'earlier',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'RBR',\n",
       "   '+1:postag[:2]': 'RB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'earlier',\n",
       "   'word[-3:]': 'ier',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'RBR',\n",
       "   'postag[:2]': 'RB',\n",
       "   '-1:word.lower()': 'candidacy',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'this',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'this',\n",
       "   'word[-3:]': 'his',\n",
       "   'word[-2:]': 'is',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'earlier',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'RBR',\n",
       "   '-1:postag[:2]': 'RB',\n",
       "   '+1:word.lower()': 'month',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'month',\n",
       "   'word[-3:]': 'nth',\n",
       "   'word[-2:]': 'th',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'this',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'when',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'WRB',\n",
       "   '+1:postag[:2]': 'WR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'when',\n",
       "   'word[-3:]': 'hen',\n",
       "   'word[-2:]': 'en',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'WRB',\n",
       "   'postag[:2]': 'WR',\n",
       "   '-1:word.lower()': 'month',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'it',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'it',\n",
       "   'word[-3:]': 'it',\n",
       "   'word[-2:]': 'it',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'when',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'WRB',\n",
       "   '-1:postag[:2]': 'WR',\n",
       "   '+1:word.lower()': 'became',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'became',\n",
       "   'word[-3:]': 'ame',\n",
       "   'word[-2:]': 'me',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'it',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'clear',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'clear',\n",
       "   'word[-3:]': 'ear',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'became',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'parliament',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'parliament',\n",
       "   'word[-3:]': 'ent',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'clear',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'would',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'MD',\n",
       "   '+1:postag[:2]': 'MD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'would',\n",
       "   'word[-3:]': 'uld',\n",
       "   'word[-2:]': 'ld',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'MD',\n",
       "   'postag[:2]': 'MD',\n",
       "   '-1:word.lower()': 'parliament',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'reject',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'reject',\n",
       "   'word[-3:]': 'ect',\n",
       "   'word[-2:]': 'ct',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'would',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'MD',\n",
       "   '-1:postag[:2]': 'MD',\n",
       "   '+1:word.lower()': 'him',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'him',\n",
       "   'word[-3:]': 'him',\n",
       "   'word[-2:]': 'im',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'reject',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'as',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'RB',\n",
       "   '+1:postag[:2]': 'RB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'as',\n",
       "   'word[-3:]': 'as',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'RB',\n",
       "   'postag[:2]': 'RB',\n",
       "   '-1:word.lower()': 'him',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'well',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'RB',\n",
       "   '+1:postag[:2]': 'RB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'well',\n",
       "   'word[-3:]': 'ell',\n",
       "   'word[-2:]': 'll',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'RB',\n",
       "   'postag[:2]': 'RB',\n",
       "   '-1:word.lower()': 'as',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'RB',\n",
       "   '-1:postag[:2]': 'RB',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'well',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'RB',\n",
       "   '-1:postag[:2]': 'RB',\n",
       "   'EOS': True}],\n",
       " [{'bias': 1.0,\n",
       "   'word.lower()': 'this',\n",
       "   'word[-3:]': 'his',\n",
       "   'word[-2:]': 'is',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'money',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'money',\n",
       "   'word[-3:]': 'ney',\n",
       "   'word[-2:]': 'ey',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'this',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'will',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'MD',\n",
       "   '+1:postag[:2]': 'MD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'will',\n",
       "   'word[-3:]': 'ill',\n",
       "   'word[-2:]': 'll',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'MD',\n",
       "   'postag[:2]': 'MD',\n",
       "   '-1:word.lower()': 'money',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'be',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'be',\n",
       "   'word[-3:]': 'be',\n",
       "   'word[-2:]': 'be',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'will',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'MD',\n",
       "   '-1:postag[:2]': 'MD',\n",
       "   '+1:word.lower()': 'subtracted',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'subtracted',\n",
       "   'word[-3:]': 'ted',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'be',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'from',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'from',\n",
       "   'word[-3:]': 'rom',\n",
       "   'word[-2:]': 'om',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'subtracted',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'from',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'amount',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'amount',\n",
       "   'word[-3:]': 'unt',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'venezuela',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'venezuela',\n",
       "   'word[-3:]': 'ela',\n",
       "   'word[-2:]': 'la',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'amount',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'owes',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'owes',\n",
       "   'word[-3:]': 'wes',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'venezuela',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'owes',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'companies',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'companies',\n",
       "   'word[-3:]': 'ies',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'for',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'for',\n",
       "   'word[-3:]': 'for',\n",
       "   'word[-2:]': 'or',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'companies',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'taking',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBG',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'taking',\n",
       "   'word[-3:]': 'ing',\n",
       "   'word[-2:]': 'ng',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBG',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'for',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'over',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'RP',\n",
       "   '+1:postag[:2]': 'RP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'over',\n",
       "   'word[-3:]': 'ver',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'RP',\n",
       "   'postag[:2]': 'RP',\n",
       "   '-1:word.lower()': 'taking',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBG',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'their',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP$',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'their',\n",
       "   'word[-3:]': 'eir',\n",
       "   'word[-2:]': 'ir',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP$',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'over',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'RP',\n",
       "   '-1:postag[:2]': 'RP',\n",
       "   '+1:word.lower()': 'majority',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'majority',\n",
       "   'word[-3:]': 'ity',\n",
       "   'word[-2:]': 'ty',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'their',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP$',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'stakes',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'stakes',\n",
       "   'word[-3:]': 'kes',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'majority',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'stakes',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'oil',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'oil',\n",
       "   'word[-3:]': 'oil',\n",
       "   'word[-2:]': 'il',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'fields',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'fields',\n",
       "   'word[-3:]': 'lds',\n",
       "   'word[-2:]': 'ds',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'oil',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'and',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': 'fields',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'refining',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'refining',\n",
       "   'word[-3:]': 'ing',\n",
       "   'word[-2:]': 'ng',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': 'plants',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'plants',\n",
       "   'word[-3:]': 'nts',\n",
       "   'word[-2:]': 'ts',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'refining',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'plants',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'EOS': True}],\n",
       " [{'bias': 1.0,\n",
       "   'word.lower()': 'she',\n",
       "   'word[-3:]': 'She',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'said',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'said',\n",
       "   'word[-3:]': 'aid',\n",
       "   'word[-2:]': 'id',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'she',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'that',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'that',\n",
       "   'word[-3:]': 'hat',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'said',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'despite',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'despite',\n",
       "   'word[-3:]': 'ite',\n",
       "   'word[-2:]': 'te',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'that',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'two',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CD',\n",
       "   '+1:postag[:2]': 'CD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'two',\n",
       "   'word[-3:]': 'two',\n",
       "   'word[-2:]': 'wo',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   '-1:word.lower()': 'despite',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'u.n.',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'u.n.',\n",
       "   'word[-3:]': '.N.',\n",
       "   'word[-2:]': 'N.',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'two',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   '+1:word.lower()': 'chapter',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'chapter',\n",
       "   'word[-3:]': 'ter',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'u.n.',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '7',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CD',\n",
       "   '+1:postag[:2]': 'CD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '7',\n",
       "   'word[-3:]': '7',\n",
       "   'word[-2:]': '7',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': True,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   '-1:word.lower()': 'chapter',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'resolutions',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'resolutions',\n",
       "   'word[-3:]': 'ons',\n",
       "   'word[-2:]': 'ns',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': '7',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   '+1:word.lower()': '-',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '-',\n",
       "   'word[-3:]': '-',\n",
       "   'word[-2:]': '-',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'resolutions',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': '-',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'u.n.',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'u.n.',\n",
       "   'word[-3:]': '.N.',\n",
       "   'word[-2:]': 'N.',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': \"'s\",\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'POS',\n",
       "   '+1:postag[:2]': 'PO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': \"'s\",\n",
       "   'word[-3:]': \"'s\",\n",
       "   'word[-2:]': \"'s\",\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'POS',\n",
       "   'postag[:2]': 'PO',\n",
       "   '-1:word.lower()': 'u.n.',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'most',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'RBS',\n",
       "   '+1:postag[:2]': 'RB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'most',\n",
       "   'word[-3:]': 'ost',\n",
       "   'word[-2:]': 'st',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'RBS',\n",
       "   'postag[:2]': 'RB',\n",
       "   '-1:word.lower()': \"'s\",\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'POS',\n",
       "   '-1:postag[:2]': 'PO',\n",
       "   '+1:word.lower()': 'serious',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'serious',\n",
       "   'word[-3:]': 'ous',\n",
       "   'word[-2:]': 'us',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'most',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'RBS',\n",
       "   '-1:postag[:2]': 'RB',\n",
       "   '+1:word.lower()': 'security',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'security',\n",
       "   'word[-3:]': 'ity',\n",
       "   'word[-2:]': 'ty',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'serious',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'council',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'council',\n",
       "   'word[-3:]': 'cil',\n",
       "   'word[-2:]': 'il',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'security',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'resolution',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'resolution',\n",
       "   'word[-3:]': 'ion',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'council',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '-',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ':',\n",
       "   '+1:postag[:2]': ':'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '-',\n",
       "   'word[-3:]': '-',\n",
       "   'word[-2:]': '-',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ':',\n",
       "   'postag[:2]': ':',\n",
       "   '-1:word.lower()': 'resolution',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'iran',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iran',\n",
       "   'word[-3:]': 'ran',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': '-',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ':',\n",
       "   '-1:postag[:2]': ':',\n",
       "   '+1:word.lower()': 'continues',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'continues',\n",
       "   'word[-3:]': 'ues',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'iran',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'continues',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'pursue',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'pursue',\n",
       "   'word[-3:]': 'sue',\n",
       "   'word[-2:]': 'ue',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'technologies',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'technologies',\n",
       "   'word[-3:]': 'ies',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'pursue',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'that',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'WDT',\n",
       "   '+1:postag[:2]': 'WD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'that',\n",
       "   'word[-3:]': 'hat',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'WDT',\n",
       "   'postag[:2]': 'WD',\n",
       "   '-1:word.lower()': 'technologies',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'could',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'MD',\n",
       "   '+1:postag[:2]': 'MD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'could',\n",
       "   'word[-3:]': 'uld',\n",
       "   'word[-2:]': 'ld',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'MD',\n",
       "   'postag[:2]': 'MD',\n",
       "   '-1:word.lower()': 'that',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'WDT',\n",
       "   '-1:postag[:2]': 'WD',\n",
       "   '+1:word.lower()': 'lead',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'lead',\n",
       "   'word[-3:]': 'ead',\n",
       "   'word[-2:]': 'ad',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'could',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'MD',\n",
       "   '-1:postag[:2]': 'MD',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'lead',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'a',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'a',\n",
       "   'word[-3:]': 'a',\n",
       "   'word[-2:]': 'a',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'nuclear',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'nuclear',\n",
       "   'word[-3:]': 'ear',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'a',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'weapon',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'weapon',\n",
       "   'word[-3:]': 'pon',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'nuclear',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'weapon',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'EOS': True}],\n",
       " [{'bias': 1.0,\n",
       "   'word.lower()': 'a',\n",
       "   'word[-3:]': 'A',\n",
       "   'word[-2:]': 'A',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'top',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'top',\n",
       "   'word[-3:]': 'top',\n",
       "   'word[-2:]': 'op',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'a',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'u.n.',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'u.n.',\n",
       "   'word[-3:]': '.N.',\n",
       "   'word[-2:]': 'N.',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'top',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'official',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'official',\n",
       "   'word[-3:]': 'ial',\n",
       "   'word[-2:]': 'al',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'u.n.',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'says',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'says',\n",
       "   'word[-3:]': 'ays',\n",
       "   'word[-2:]': 'ys',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'official',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'indirect',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'indirect',\n",
       "   'word[-3:]': 'ect',\n",
       "   'word[-2:]': 'ct',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'says',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'talks',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'talks',\n",
       "   'word[-3:]': 'lks',\n",
       "   'word[-2:]': 'ks',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'indirect',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'between',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'between',\n",
       "   'word[-3:]': 'een',\n",
       "   'word[-2:]': 'en',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'talks',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'between',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'ugandan',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'ugandan',\n",
       "   'word[-3:]': 'dan',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'government',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'government',\n",
       "   'word[-3:]': 'ent',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'ugandan',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'and',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': 'government',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'northern',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'northern',\n",
       "   'word[-3:]': 'ern',\n",
       "   'word[-2:]': 'rn',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': 'rebels',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'rebels',\n",
       "   'word[-3:]': 'els',\n",
       "   'word[-2:]': 'ls',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'northern',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'have',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'have',\n",
       "   'word[-3:]': 'ave',\n",
       "   'word[-2:]': 've',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'rebels',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'provided',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'provided',\n",
       "   'word[-3:]': 'ded',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'have',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'provided',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'best',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJS',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'best',\n",
       "   'word[-3:]': 'est',\n",
       "   'word[-2:]': 'st',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJS',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'chance',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'chance',\n",
       "   'word[-3:]': 'nce',\n",
       "   'word[-2:]': 'ce',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'best',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJS',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'for',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'for',\n",
       "   'word[-3:]': 'for',\n",
       "   'word[-2:]': 'or',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'chance',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'peace',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'peace',\n",
       "   'word[-3:]': 'ace',\n",
       "   'word[-2:]': 'ce',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'for',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'peace',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '18',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CD',\n",
       "   '+1:postag[:2]': 'CD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '18',\n",
       "   'word[-3:]': '18',\n",
       "   'word[-2:]': '18',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': True,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'years',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'years',\n",
       "   'word[-3:]': 'ars',\n",
       "   'word[-2:]': 'rs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': '18',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'years',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'conflict',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'conflict',\n",
       "   'word[-3:]': 'ict',\n",
       "   'word[-2:]': 'ct',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'conflict',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'EOS': True}],\n",
       " [{'bias': 1.0,\n",
       "   'word.lower()': 'thai',\n",
       "   'word[-3:]': 'hai',\n",
       "   'word[-2:]': 'ai',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'prime',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'prime',\n",
       "   'word[-3:]': 'ime',\n",
       "   'word[-2:]': 'me',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'thai',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'minister',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'minister',\n",
       "   'word[-3:]': 'ter',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'prime',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'thaksin',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'thaksin',\n",
       "   'word[-3:]': 'sin',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'minister',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'shinawatra',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'shinawatra',\n",
       "   'word[-3:]': 'tra',\n",
       "   'word[-2:]': 'ra',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'thaksin',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'has',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'has',\n",
       "   'word[-3:]': 'has',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'shinawatra',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'said',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'said',\n",
       "   'word[-3:]': 'aid',\n",
       "   'word[-2:]': 'id',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'has',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'he',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'he',\n",
       "   'word[-3:]': 'he',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'said',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'believes',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'believes',\n",
       "   'word[-3:]': 'ves',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'he',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'some',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'some',\n",
       "   'word[-3:]': 'ome',\n",
       "   'word[-2:]': 'me',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'believes',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'some',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'insurgents',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'insurgents',\n",
       "   'word[-3:]': 'nts',\n",
       "   'word[-2:]': 'ts',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'have',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'have',\n",
       "   'word[-3:]': 'ave',\n",
       "   'word[-2:]': 've',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'insurgents',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'been',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'been',\n",
       "   'word[-3:]': 'een',\n",
       "   'word[-2:]': 'en',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'have',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'trained',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'trained',\n",
       "   'word[-3:]': 'ned',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'been',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'trained',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'malaysia',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'malaysia',\n",
       "   'word[-3:]': 'sia',\n",
       "   'word[-2:]': 'ia',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'malaysia',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'indonesia',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'indonesia',\n",
       "   'word[-3:]': 'sia',\n",
       "   'word[-2:]': 'ia',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'and',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': 'indonesia',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'southern',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'southern',\n",
       "   'word[-3:]': 'ern',\n",
       "   'word[-2:]': 'rn',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': 'thailand',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'thailand',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'southern',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'thailand',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'EOS': True}]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(path_export + '/ner_v1.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 50,\n",
       " 'scores': {},\n",
       " 'loss': 6485.580681,\n",
       " 'feature_norm': 52.650711,\n",
       " 'error_norm': 108.470127,\n",
       " 'active_features': 3938,\n",
       " 'linesearch_trials': 1,\n",
       " 'linesearch_step': 1.0,\n",
       " 'time': 0.12}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 {'num': 50, 'scores': {}, 'loss': 6485.580681, 'feature_norm': 52.650711, 'error_norm': 108.470127, 'active_features': 3938, 'linesearch_trials': 1, 'linesearch_step': 1.0, 'time': 0.12}\n"
     ]
    }
   ],
   "source": [
    "print(len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "To use the trained model, create pycrfsuite.Tagger, open the model and use \"tag\" method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f846dd4c1f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(path_export + '/ner_v1.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tag a sentence to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = [sent2features(s) for s in sentences]\n",
    "# y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: O O O O O O O O B-tim O O O O O O O O O O O O O O O O B-tim O\n"
     ]
    }
   ],
   "source": [
    "example_sent = X_test[0]\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(example_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict entity labels for all sentences in our testing set ('testb' Spanish data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..and check the result. Note this report is not comparable to results in CONLL2002 papers because here we check per-token results (not per-entity). Per-entity numbers will be worse.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check what classifier learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized. Also note I-PER -> B-LOC transition: a positive weight means that model thinks that a person name is often followed by a location.\n",
    "\n",
    "Check the state features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sentences[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word.lower()': 'thousands',\n",
       "  'word[-3:]': 'nds',\n",
       "  'word[-2:]': 'ds',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  'BOS': True,\n",
       "  '+1:word.lower()': 'of',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'of',\n",
       "  'word[-3:]': 'of',\n",
       "  'word[-2:]': 'of',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'thousands',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'demonstrators',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNS',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'demonstrators',\n",
       "  'word[-3:]': 'ors',\n",
       "  'word[-2:]': 'rs',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'of',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'have',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VBP',\n",
       "  '+1:postag[:2]': 'VB'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'have',\n",
       "  'word[-3:]': 'ave',\n",
       "  'word[-2:]': 've',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VBP',\n",
       "  'postag[:2]': 'VB',\n",
       "  '-1:word.lower()': 'demonstrators',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'marched',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VBN',\n",
       "  '+1:postag[:2]': 'VB'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'marched',\n",
       "  'word[-3:]': 'hed',\n",
       "  'word[-2:]': 'ed',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VBN',\n",
       "  'postag[:2]': 'VB',\n",
       "  '-1:word.lower()': 'have',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VBP',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '+1:word.lower()': 'through',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'through',\n",
       "  'word[-3:]': 'ugh',\n",
       "  'word[-2:]': 'gh',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'marched',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VBN',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '+1:word.lower()': 'london',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'london',\n",
       "  'word[-3:]': 'don',\n",
       "  'word[-2:]': 'on',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'through',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'to',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'TO',\n",
       "  '+1:postag[:2]': 'TO'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'to',\n",
       "  'word[-3:]': 'to',\n",
       "  'word[-2:]': 'to',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'TO',\n",
       "  'postag[:2]': 'TO',\n",
       "  '-1:word.lower()': 'london',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNP',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'protest',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VB',\n",
       "  '+1:postag[:2]': 'VB'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'protest',\n",
       "  'word[-3:]': 'est',\n",
       "  'word[-2:]': 'st',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VB',\n",
       "  'postag[:2]': 'VB',\n",
       "  '-1:word.lower()': 'to',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'TO',\n",
       "  '-1:postag[:2]': 'TO',\n",
       "  '+1:word.lower()': 'the',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'the',\n",
       "  'word[-3:]': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  '-1:word.lower()': 'protest',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VB',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '+1:word.lower()': 'war',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'war',\n",
       "  'word[-3:]': 'war',\n",
       "  'word[-2:]': 'ar',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'the',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '+1:word.lower()': 'in',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'in',\n",
       "  'word[-3:]': 'in',\n",
       "  'word[-2:]': 'in',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'war',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'iraq',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'iraq',\n",
       "  'word[-3:]': 'raq',\n",
       "  'word[-2:]': 'aq',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'in',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'and',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'CC',\n",
       "  '+1:postag[:2]': 'CC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'and',\n",
       "  'word[-3:]': 'and',\n",
       "  'word[-2:]': 'nd',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'CC',\n",
       "  'postag[:2]': 'CC',\n",
       "  '-1:word.lower()': 'iraq',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNP',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'demand',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VB',\n",
       "  '+1:postag[:2]': 'VB'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'demand',\n",
       "  'word[-3:]': 'and',\n",
       "  'word[-2:]': 'nd',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VB',\n",
       "  'postag[:2]': 'VB',\n",
       "  '-1:word.lower()': 'and',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'CC',\n",
       "  '-1:postag[:2]': 'CC',\n",
       "  '+1:word.lower()': 'the',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'the',\n",
       "  'word[-3:]': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  '-1:word.lower()': 'demand',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VB',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '+1:word.lower()': 'withdrawal',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'withdrawal',\n",
       "  'word[-3:]': 'wal',\n",
       "  'word[-2:]': 'al',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'the',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '+1:word.lower()': 'of',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'of',\n",
       "  'word[-3:]': 'of',\n",
       "  'word[-2:]': 'of',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'withdrawal',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'british',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'JJ',\n",
       "  '+1:postag[:2]': 'JJ'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'british',\n",
       "  'word[-3:]': 'ish',\n",
       "  'word[-2:]': 'sh',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'JJ',\n",
       "  'postag[:2]': 'JJ',\n",
       "  '-1:word.lower()': 'of',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'troops',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNS',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'troops',\n",
       "  'word[-3:]': 'ops',\n",
       "  'word[-2:]': 'ps',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'british',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'JJ',\n",
       "  '-1:postag[:2]': 'JJ',\n",
       "  '+1:word.lower()': 'from',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'from',\n",
       "  'word[-3:]': 'rom',\n",
       "  'word[-2:]': 'om',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'troops',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'that',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'that',\n",
       "  'word[-3:]': 'hat',\n",
       "  'word[-2:]': 'at',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  '-1:word.lower()': 'from',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'country',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'country',\n",
       "  'word[-3:]': 'try',\n",
       "  'word[-2:]': 'ry',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'that',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '+1:word.lower()': '.',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': '.',\n",
       "  '+1:postag[:2]': '.'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': '.',\n",
       "  'word[-3:]': '.',\n",
       "  'word[-2:]': '.',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': '.',\n",
       "  'postag[:2]': '.',\n",
       "  '-1:word.lower()': 'country',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
