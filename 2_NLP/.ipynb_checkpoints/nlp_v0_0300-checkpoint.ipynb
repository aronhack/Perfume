{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "from ckiptagger import construct_dictionary\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "host = 4\n",
    "host = 0\n",
    "\n",
    "if host == 0:\n",
    "    path = r'/Users/aron/Documents/GitHub/Perfume/2_NLP'\n",
    "    dict_file = r'/Users/aron/Documents/GitHub/Perfume/1_Crawler/Resource/dict.xlsx'\n",
    "    data_file = r'/Users/aron/Documents/GitHub/Perfume/1_Crawler/Resource/data.xls'\n",
    "    \n",
    "elif host == 4:\n",
    "    path = r'/home/rserver/Data_Mining/personal_workspace/yz/Lab/CkipTagger/'\n",
    "    dict_file = r'/home/rserver/Data_Mining/personal_workspace/yz/Lab/CkipTagger/Resource/dict.xlsx'\n",
    "    data_file = r'/home/rserver/Data_Mining/personal_workspace/yz/Lab/CkipTagger/Resource/data.xls'\n",
    "\n",
    "    \n",
    "# Codebase ......\n",
    "path_codebase = [r'/Users/aron/Documents/GitHub/Arsenal/',\n",
    "                 r'/home/aronhack/stock_predict/Function',\n",
    "                 r'D:\\GitHub\\Arsenal',\n",
    "                 r'D:\\Data_Mining\\Projects\\Codebase_YZ',\n",
    "                 r'/home/jupyter/Arsenal/20220522',\n",
    "                 path + '/Function']\n",
    "\n",
    "\n",
    "for i in path_codebase:    \n",
    "    if i not in sys.path:\n",
    "        sys.path = [i] + sys.path\n",
    "    \n",
    "\n",
    "import codebase_yz as cbyz\n",
    "    \n",
    "    \n",
    "path_resource = path + '/Resource'\n",
    "path_export = path + '/Export'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Custom Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = pd.read_excel(dict_file)    \n",
    "dict_li = dict_df['word'].tolist()\n",
    "custom_dict = dict((el, 1) for el in dict_li)\n",
    "custom_dict = construct_dictionary(custom_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:984: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._kernel = self.add_variable(\n",
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:993: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._bias = self.add_variable(\n",
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "/Users/aron/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    }
   ],
   "source": [
    "# 2. Load model\n",
    "# To use GPU:\n",
    "#    1. Install tensorflow-gpu (see Installation)\n",
    "#    2. Set CUDA_VISIBLE_DEVICES environment variable, e.g. os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#    3. Set disable_cuda=False, e.g. ws = WS(\"./data\", disable_cuda=False)\n",
    "# To use CPU:\n",
    "# https://drive.google.com/drive/folders/105IKCb88evUyLKlLondvDBoh7Dy_I1tm\n",
    "\n",
    "ws = WS(path_resource + \"/data\")\n",
    "pos = POS(path_resource + \"/data\")\n",
    "ner = NER(path_resource + \"/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the WS-POS-NER pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(data_file)\n",
    "data = data.dropna(subset=['title'], axis=0)\n",
    "data = data[~data['title'].str.contains('廣告')]\n",
    "\n",
    "# data = data[~data['name'].isna()]\n",
    "# data = data[data.index<=300]\n",
    "\n",
    "data = data.dropna(subset=['title'], axis=0)\n",
    "data['title'] = data['title'].str.replace('找相似', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = data['title'].tolist()\n",
    "\n",
    "# y = data['name'].tolist()\n",
    "y = data['brand'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Manually\n",
    "data = data[data['title'].str.contains(' 萬寶龍星際旅者男性淡香水')]\n",
    "sentence_list = data['title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sentence_list = ws(\n",
    "    sentence_list,\n",
    "    # sentence_segmentation = True, # To consider delimiters\n",
    "    # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}), # This is the defualt set of delimiters\n",
    "    # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "    coerce_dictionary = custom_dict, # words in this dictionary are forced\n",
    ")\n",
    "\n",
    "pos_sentence_list = pos(word_sentence_list)\n",
    "entity_sentence_list = ner(word_sentence_list, pos_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>HUAHUA</td>\n",
       "      <td>FW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>香水</td>\n",
       "      <td>Na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>美妝</td>\n",
       "      <td>Na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Montblanc</td>\n",
       "      <td>FW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Starwalker</td>\n",
       "      <td>FW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>已</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>售出</td>\n",
       "      <td>VC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>FW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>雲林縣</td>\n",
       "      <td>Nc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>西螺鎮</td>\n",
       "      <td>Nc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence         word pos tag\n",
       "0          0       HUAHUA  FW   0\n",
       "1          0           香水  Na   0\n",
       "2          0           美妝  Na   0\n",
       "3          0   Montblanc   FW   0\n",
       "4          0  Starwalker   FW   0\n",
       "..       ...          ...  ..  ..\n",
       "19         4            已   D   0\n",
       "20         4           售出  VC   0\n",
       "21         4            6  FW   0\n",
       "22         4          雲林縣  Nc   0\n",
       "23         4          西螺鎮  Nc   0\n",
       "\n",
       "[123 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i, sentence in enumerate(sentence_list):\n",
    "    \n",
    "    new_li = list(zip(word_sentence_list[i],  pos_sentence_list[i]))\n",
    "    cur_y = y[i]\n",
    "    \n",
    "    temp_df = pd.DataFrame(new_li, columns=['word', 'pos'])\n",
    "    temp_df['sentence'] = i\n",
    "    temp_df['tag'] = np.where(temp_df['word']==cur_y, '1', '0')\n",
    "    \n",
    "    df = df.append(temp_df)\n",
    "    \n",
    "df = df[['sentence', 'word', 'pos', 'tag']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence, word, pos, tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tag']=='1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Show Results\n",
    "def print_word_pos_sentence(word_sentence, pos_sentence):\n",
    "    assert len(word_sentence) == len(pos_sentence)\n",
    "    for word, pos in zip(word_sentence, pos_sentence):\n",
    "        print(f\"{word}({pos})\", end=\"\\u3000\")\n",
    "    print()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence, word, pos, tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_sentence_list[0]\n",
    "# pos_sentence_list[0]\n",
    "\n",
    "df[df['tag']=='1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'HUAHUA香水美妝 Montblanc Starwalker 萬寶龍星際旅者男性淡香水 50 75ML 【全新正品】$880 - $930已售出 433臺北市中山區'\n",
      "HUAHUA(FW)　香水(Na)　美妝(Na)　 Montblanc (FW)　Starwalker (FW)　萬寶龍(Nb)　星際(Nc)　旅者(Na)　男性(Na)　淡香水(Na)　 (WHITESPACE)　50(Neu)　 (WHITESPACE)　75(Neu)　ML (FW)　【(PARENTHESISCATEGORY)　全新(VH)　正品(Na)　】(PARENTHESISCATEGORY)　$(FW)　880(Neu)　 - $(FW)　930(Nd)　已(D)　售出(VC)　 433(FW)　臺北市(Nc)　中山區(Nc)　\n",
      "(32, 35, 'PRODUCT', '萬寶龍')\n",
      "(45, 47, 'CARDINAL', '50')\n",
      "(77, 80, 'GPE', '臺北市')\n",
      "(80, 83, 'LOC', '中山區')\n",
      "'MONTBLANC 萬寶龍星際旅者男性淡香水75ml滿額折$30$850已售出 8嘉義市東區'\n",
      "MONTBLANC(FW)　 (WHITESPACE)　萬寶龍(Nb)　星際(Nc)　旅者(Na)　男性(Na)　淡香水(Na)　75(Neu)　ml(Nf)　滿額(VH)　折$(VC)　30(Neu)　$(FW)　850(Neu)　已(D)　售出(VC)　 8(FW)　嘉義市(Nc)　東區(Nc)　\n",
      "(0, 13, 'PRODUCT', 'MONTBLANC 萬寶龍')\n",
      "(22, 26, 'QUANTITY', '75ml')\n",
      "(30, 36, 'MONEY', '30$850')\n",
      "(39, 44, 'GPE', ' 8嘉義市')\n",
      "'蝦皮優選Montblanc Starwalker 萬寶龍星際旅者男性淡香水 75ml 50ml 另有TESTER【金多利美妝】$880 - $990已售出 28新北市板橋區'\n",
      "蝦皮(Na)　優選(Na)　Montblanc (FW)　Starwalker (FW)　萬寶龍(Nb)　星際(Nc)　旅者(Na)　男性(Na)　淡香水(Na)　 (WHITESPACE)　75(Neu)　ml (Nf)　50(Neu)　ml (Nf)　另(Nes)　有(V_2)　TESTER(FW)　【(PARENTHESISCATEGORY)　金多利(Nb)　美妝(Na)　】(PARENTHESISCATEGORY)　$(FW)　880(Neu)　 - $(FW)　990(Nd)　已(D)　售出(VC)　 28(FW)　新北市(Nc)　板橋區(Nc)　\n",
      "(25, 28, 'PRODUCT', '萬寶龍')\n",
      "(78, 80, 'DATE', '28')\n",
      "(80, 86, 'GPE', '新北市板橋區')\n",
      "'”代理商公司貨”Montblanc Starwalker 萬寶龍星際旅者男性淡香水50ML/75ML$880 - $990嘉義縣大林鎮'\n",
      "”(VG)　代理商(Na)　公司貨(Na)　”(VG)　Montblanc (FW)　Starwalker (FW)　萬寶龍(Nb)　星際(Nc)　旅(VCL)　者(Na)　男性(Na)　淡香水(Na)　50(Neu)　ML/(FW)　75(Neu)　ML(Nf)　$(FW)　880(Neu)　 - $(FW)　990(Neu)　嘉義縣(Nc)　大林鎮(Nc)　\n",
      "(29, 32, 'PRODUCT', '萬寶龍')\n",
      "(61, 67, 'GPE', '嘉義縣大林鎮')\n",
      "'分享香 Montblanc Starwalker 萬寶龍星際旅者男性淡香水分裝香5ml.10ml$65已售出 6雲林縣西螺鎮'\n",
      "分享(VJ)　香 (FW)　Montblanc (FW)　Starwalker (FW)　萬寶龍(Nb)　星際(Nc)　旅(VCL)　者(Na)　男性(Na)　淡香水(Na)　分(VC)　裝香(Na)　5(Neu)　ml(Nf)　.(PERIODCATEGORY)　10(Neu)　ml(Nf)　$(FW)　65(Neu)　已(D)　售出(VC)　 6(FW)　雲林縣(Nc)　西螺鎮(Nc)　\n",
      "(25, 28, 'PRODUCT', '萬寶龍')\n",
      "(40, 43, 'QUANTITY', '5ml')\n",
      "(44, 51, 'QUANTITY', '10ml$65')\n",
      "(56, 62, 'GPE', '雲林縣西螺鎮')\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(sentence_list):\n",
    "#     print()\n",
    "    print(f\"'{sentence}'\")\n",
    "    print_word_pos_sentence(word_sentence_list[i],  pos_sentence_list[i])\n",
    "    for entity in sorted(entity_sentence_list[i]):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['word'].values.tolist(), \n",
    "                                                           s['pos'].values.tolist(), \n",
    "                                                           s['tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('sentence').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        \n",
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split train and test sets\n",
    "X = [sent2features(s) for s in sentences]\n",
    "new_y = [sent2labels(s) for s in sentences]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, new_y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "#     'c1': 1.0,   # coefficient for L1 penalty\n",
    "#     'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(path_export + '/ckip_tagger_model.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2b983223a8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "To use the trained model, create pycrfsuite.Tagger, open the model and use \"tag\" method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7fa64704ef70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(path_export + '/ckip_tagger_model.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tag a sentence to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(len(y_test)):\n",
    "    new_pred = tagger.tag(X_test[i])\n",
    "    y_pred.append(new_pred)\n",
    "#     example_sent = X_test[i]\n",
    "#     print(\"Predicted:\", ' '.join(tagger.tag(X_test[i])))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cbyz.li_flatten(y_pred)\n",
    "y_test = cbyz.li_flatten(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(y_pred)\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-98d1c8585ead>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-98d1c8585ead>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    y_test[i for i in y_test]\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_test[i for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "\n",
      "    accuracy                           1.00        58\n",
      "   macro avg       1.00      1.00      1.00        58\n",
      "weighted avg       1.00      1.00      1.00        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "# print(classification_report(y_pred=y_pred, y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check what classifier learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "\n",
      "Top unlikely transitions:\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized. Also note I-PER -> B-LOC transition: a positive weight means that model thinks that a person name is often followed by a location.\n",
    "\n",
    "Check the state features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "\n",
      "Top negative:\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import matutils\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        path_resource + '/tmunlp_1.6B_WB_50dim_2020v1.bin.gz', \n",
    "        unicode_errors='ignore',\n",
    "        binary=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [0]:\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in range(len(word_sentence_list)):\n",
    "\n",
    "    word_vec = {}\n",
    "    for w in word_sentence_list[i]:\n",
    "        try:\n",
    "            word_vec[w] = model.get_vector(w)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Create DF\n",
    "    keys = list(word_vec.keys())\n",
    "    vec_df = pd.DataFrame({'word':keys,\n",
    "                          'index':range(len(keys))})\n",
    "\n",
    "    vec_df = cbyz.df_cross_join(vec_df, vec_df)\n",
    "    vec_df = vec_df[vec_df['index_x']<vec_df['index_y']] \\\n",
    "            .reset_index(drop=True) \n",
    "    \n",
    "    for j in range(len(vec_df)):\n",
    "        vec1 = model.get_vector(vec_df.loc[j, 'word_x'])\n",
    "        vec2 = model.get_vector(vec_df.loc[j, 'word_y'])\n",
    "        similarity = np.dot(matutils.unitvec(vec1), matutils.unitvec(vec2))\n",
    "        vec_df.loc[j, 'similarity'] = similarity\n",
    "\n",
    "    result = result.append(vec_df)\n",
    "    \n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_x</th>\n",
       "      <th>index_x</th>\n",
       "      <th>word_y</th>\n",
       "      <th>index_y</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>香水</td>\n",
       "      <td>0</td>\n",
       "      <td>美妝</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>香水</td>\n",
       "      <td>0</td>\n",
       "      <td>萬寶龍</td>\n",
       "      <td>2</td>\n",
       "      <td>0.540556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>香水</td>\n",
       "      <td>0</td>\n",
       "      <td>星際</td>\n",
       "      <td>3</td>\n",
       "      <td>0.217685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>香水</td>\n",
       "      <td>0</td>\n",
       "      <td>旅者</td>\n",
       "      <td>4</td>\n",
       "      <td>0.247153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>香水</td>\n",
       "      <td>0</td>\n",
       "      <td>男性</td>\n",
       "      <td>5</td>\n",
       "      <td>0.375379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>已</td>\n",
       "      <td>14</td>\n",
       "      <td>雲林縣</td>\n",
       "      <td>16</td>\n",
       "      <td>0.205428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>已</td>\n",
       "      <td>14</td>\n",
       "      <td>西螺鎮</td>\n",
       "      <td>17</td>\n",
       "      <td>0.045617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>售出</td>\n",
       "      <td>15</td>\n",
       "      <td>雲林縣</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.039614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>售出</td>\n",
       "      <td>15</td>\n",
       "      <td>西螺鎮</td>\n",
       "      <td>17</td>\n",
       "      <td>0.002110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>雲林縣</td>\n",
       "      <td>16</td>\n",
       "      <td>西螺鎮</td>\n",
       "      <td>17</td>\n",
       "      <td>0.703390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>869 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_x  index_x word_y  index_y  similarity\n",
       "0       香水        0     美妝        1    0.564827\n",
       "1       香水        0    萬寶龍        2    0.540556\n",
       "2       香水        0     星際        3    0.217685\n",
       "3       香水        0     旅者        4    0.247153\n",
       "4       香水        0     男性        5    0.375379\n",
       "..     ...      ...    ...      ...         ...\n",
       "864      已       14    雲林縣       16    0.205428\n",
       "865      已       14    西螺鎮       17    0.045617\n",
       "866     售出       15    雲林縣       16   -0.039614\n",
       "867     售出       15    西螺鎮       17    0.002110\n",
       "868    雲林縣       16    西螺鎮       17    0.703390\n",
       "\n",
       "[869 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.vectors\n",
    "# model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 跟淡香水之間的距離\n",
    "#   和男性、女性、中性的距離\n",
    "# - 如果title中同時出現「淡香水」、「淡香精」就排除"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
